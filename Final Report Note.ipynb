{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Report Notes and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, we can integrate these models (SVM, LR, XGBoost, LightGBM, CNN, and LSTM) with Enhanced Genetic Algorithms (EGA) and Extended Grid Search to find Pareto-optimal solutions. Here’s how we can approach it step-by-step:\n",
    "\n",
    "1. Prepare the Dataset\n",
    "\n",
    "\t•\tEnsure the data is clean, normalized, and transformed into a suitable format for each model.\n",
    "\t•\tFor models like CNN and LSTM, reshape the data to fit their input requirements (e.g., 3D tensors for LSTM).\n",
    "\n",
    "2. Baseline Model Training\n",
    "\n",
    "\t•\tTrain each model individually with default hyperparameters to get a baseline performance on the primary objectives (maximize HDI, minimize CO2 emissions, and material footprint).\n",
    "\t•\tEvaluate the models using accuracy, precision, recall, F1-score, or other relevant metrics.\n",
    "\n",
    "3. Enhanced Genetic Algorithm (EGA) + Extended Grid Search\n",
    "\n",
    "\t•\tImplement EGA as a meta-optimization layer over the models to find the best combination of hyperparameters and decision variables.\n",
    "\t•\tUse Extended Grid Search to refine hyperparameters dynamically.\n",
    "\t•\tDefine a multi-objective fitness function to evaluate each solution’s trade-offs.\n",
    "\n",
    "4. Pareto-Optimal Solution Search\n",
    "\n",
    "\t•\tUse the following approach to evaluate Pareto-optimal solutions:\n",
    "\t•\tPareto Front Calculation: Calculate the non-dominated set of solutions based on the three objectives.\n",
    "\t•\tMulti-Objective Optimization: Use a Pareto-based fitness calculation in EGA that simultaneously evaluates HDI maximization and CO2/material footprint minimization.\n",
    "\t•\tHypervolume Metric: Measure the Pareto front’s hypervolume to quantify the solution space’s improvement.\n",
    "\n",
    "5. Model Integration with EGA\n",
    "\n",
    "\t•\tIntegrate each model into the EGA:\n",
    "\t•\tSVM and LR: Use linear kernels and standard parameter tuning to integrate with EGA.\n",
    "\t•\tXGBoost and LightGBM: Tune learning rates, depth, estimators, etc., with EGA.\n",
    "\t•\tCNN and LSTM: Optimize layer parameters, filter sizes, and dropout rates using EGA.\n",
    "\n",
    "6. Evaluation of Pareto-Optimal Solutions\n",
    "\n",
    "\t•\tVisualize the Pareto front showing different solutions.\n",
    "\t•\tCompare the best solutions across models to determine which model achieves the best trade-off.\n",
    "\t•\tAnalyze the impact of each variable and its trade-off with others, focusing on HDI, CO2, and material footprint.\n",
    "\n",
    "7. Further Analysis and Insights\n",
    "\n",
    "\t•\tUse the selected models to further analyze the effects of policies or interventions that maximize human development while minimizing environmental impact.\n",
    "\t•\tDerive insights from the Pareto-optimal solutions to provide policy recommendations.\n",
    "\n",
    "Would you like to proceed with integrating these models step-by-step, starting with a specific model? Or would you like more details about how to set up each model’s integration with EGA and Extended Grid Search?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given our objective of multi-objective optimization (maximizing HDI, minimizing CO2 emissions per capita, and minimizing material footprint per capita), we need models that effectively handle non-linear relationships, interpretability, and time-series forecasting in the context of human development and environmental sustainability.\n",
    "\n",
    "Best 3 Models for Our Goal:\n",
    "\n",
    "\n",
    "Based on the dataset and the project requirements, the top 3 models for integration with Enhanced Genetic Algorithms (EGA) and Extended Grid Search are:\n",
    "\n",
    "\t1.\tXGBoost (Extreme Gradient Boosting)\n",
    "\t•\tWhy XGBoost?\n",
    "\t•\tIt’s powerful for non-linear relationships, which are common in human development and sustainability indicators.\n",
    "\t•\tIt provides robust feature importance, helping in interpretability, which is critical to understanding the effect of different variables on HDI, CO2, and material footprint.\n",
    "\t•\tIt works well with large datasets, which suits the time-series data available from 1990-2021.\n",
    "\t•\tHow to Integrate with EGA?\n",
    "\t•\tUse EGA to optimize XGBoost hyperparameters like learning_rate, max_depth, and n_estimators.\n",
    "\t•\tMulti-objective optimization: Set up EGA to maximize HDI and minimize CO2/material footprint in the context of XGBoost predictions.\n",
    "\n",
    "\n",
    "\t2.\tLightGBM (Light Gradient Boosting Machine)\n",
    "\t•\tWhy LightGBM?\n",
    "\t•\tIt is similar to XGBoost but is optimized for speed and handles categorical variables well.\n",
    "\t•\tIt’s efficient with memory usage, making it suitable for complex optimization in EGA.\n",
    "\t•\tLightGBM can handle time-series features effectively and offers interpretability.\n",
    "\t•\tHow to Integrate with EGA?\n",
    "\t•\tUse EGA to optimize hyperparameters such as num_leaves, max_depth, learning_rate, and min_child_samples.\n",
    "\t•\tFocus on multi-objective optimization to maximize HDI and minimize environmental impacts, similar to XGBoost.\n",
    "\n",
    "\n",
    "\t3.\tLSTM (Long Short-Term Memory)\n",
    "\t•\tWhy LSTM?\n",
    "\t•\tLSTM excels at capturing long-term dependencies in time-series data, which aligns well with the historical data from 1990 to 2021.\n",
    "\t•\tIt’s suitable for sequential predictions, helping to forecast trends in HDI, CO2, and material footprint based on past data.\n",
    "\t•\tIt can handle both linear and non-linear dynamics in the dataset, making it versatile.\n",
    "\t•\tHow to Integrate with EGA?\n",
    "\t•\tUse EGA to optimize parameters like the number of layers, units per layer, batch size, learning rate, and dropout rate.\n",
    "\t•\tImplement multi-objective optimization in the context of sequential prediction to maintain the focus on the three objectives.\n",
    "\n",
    "    \n",
    "\n",
    "How to Integrate These Models with EGA and Extended Grid Search:\n",
    "\n",
    "\t1.\tDefine Fitness Function for Each Model:\n",
    "\t•\tIn EGA, the fitness function will measure the models’ performance for HDI maximization and CO2/material footprint minimization.\n",
    "\t•\tUse EGA to find the optimal combination of hyperparameters that improve the trade-off among the objectives.\n",
    "\n",
    "\t2.\tImplement Extended Grid Search for Refinement:\n",
    "\t•\tAfter EGA identifies the initial set of optimal hyperparameters, use Extended Grid Search to further fine-tune hyperparameters within the optimal range.\n",
    "\n",
    "\t3.\tFind Pareto-Optimal Solutions:\n",
    "\t•\tUse multi-objective optimization techniques in EGA to identify Pareto-optimal solutions.\n",
    "\t•\tVisualize the Pareto front and analyze the trade-offs between human development and environmental sustainability.\n",
    "\n",
    "\n",
    "\n",
    "Plan of Action:\n",
    "\n",
    "\t1.\tData Preparation:\n",
    "\t•\tEnsure the data is reshaped as required by XGBoost, LightGBM, and LSTM.\n",
    "\t•\tNormalize and scale the data for better performance across models.\n",
    "\n",
    "\t2.\tInitial Model Setup:\n",
    "\t•\tImplement the three models individually to establish baseline performance.\n",
    "\t•\tUse EGA as the meta-optimizer to enhance the performance of each model based on the fitness function.\n",
    "\n",
    "\t3.\tMulti-Objective EGA Implementation:\n",
    "\t•\tApply EGA to all three models to find the best hyperparameters that improve the fitness function (maximize HDI, minimize CO2 and material footprint).\n",
    "\n",
    "\t4.\tPareto Front Visualization:\n",
    "\t•\tPlot the Pareto front for the models to visualize the trade-offs among the objectives.\n",
    "    \n",
    "\t5.\tFinal Analysis:\n",
    "\t•\tAnalyze the best-performing model(s) based on Pareto-optimal solutions.\n",
    "\t•\tDerive insights for policy recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Summary So Far\n",
    "\n",
    "We have been developing a multi-objective optimization model using Enhanced Genetic Algorithms (EGA), Extended Grid Search, and three advanced machine learning models (XGBoost, LightGBM, and LSTM) to optimize human development and environmental sustainability indicators. Here’s a breakdown of what we’ve achieved and where we stand:\n",
    "\n",
    "Key Objectives of the Project\n",
    "\n",
    "\t1.\tOptimize Human Development Index (HDI):\n",
    "\t•\tAim to maximize HDI, which reflects improved life expectancy, education, and income levels.\n",
    "\t2.\tMinimize Environmental Impact:\n",
    "\t•\tMinimize CO2 emissions per capita (reflecting lower carbon emissions).\n",
    "\t•\tMinimize material footprint per capita (indicating more sustainable resource use).\n",
    "\n",
    "The core challenge is to find Pareto-optimal solutions that balance improvements in human development while minimizing environmental impacts. This involves finding trade-offs, as enhancing HDI often conflicts with reducing CO2 emissions and material footprint.\n",
    "\n",
    "Step-by-Step Progress\n",
    "\n",
    "\t1.\tData Preparation & Feature Engineering:\n",
    "\t•\tDataset Loaded: We loaded the Human Development Index Dataset (1990-2021), containing various indicators such as HDI, CO2 emissions, material footprint, and other gender-specific indicators.\n",
    "\t•\tFeature Engineering: Calculated additional metrics like rolling averages, growth rates, and disparities (e.g., HDI growth, GNI growth, gender disparities).\n",
    "\t•\tData Preprocessing: Normalized and reshaped the data to align with the requirements of different models, especially LSTM, which requires 3D input.\n",
    "\t2.\tInitial Exploration with Enhanced Genetic Algorithm (EGA):\n",
    "\t•\tEGA was applied to generate an initial set of solutions, finding the best combination of features that optimize HDI while minimizing CO2 and material footprint.\n",
    "\t•\tFitness Scores: Calculated using a defined fitness function that integrates the three objectives.\n",
    "\t•\tMulti-Objective Optimization: EGA provided initial solutions representing potential trade-offs, setting up the baseline for further modeling.\n",
    "\t3.\tModel Integration and Extended Grid Search:\n",
    "\t•\tXGBoost: Implemented as the first machine learning model.\n",
    "\t•\tAchieved a validation R² score of ~0.723 with a MSE of ~0.0207, indicating that it captured the non-linear relationships reasonably well.\n",
    "\t•\tHyperparameters were optimized using EGA to achieve better performance in balancing the three objectives.\n",
    "\t•\tLightGBM: Integrated next.\n",
    "\t•\tAchieved a validation R² score of ~0.748 with a RMSE of ~0.137, indicating better performance compared to XGBoost in handling trade-offs.\n",
    "\t•\tSimilarly, EGA was used to optimize LightGBM’s hyperparameters for multi-objective performance.\n",
    "\t•\tLSTM: We attempted to implement this model to leverage time-series data.\n",
    "\t•\tThe model faced issues with input reshaping, which we resolved by correcting the input shape to the format required by LSTM (samples, timesteps, features).\n",
    "\t•\tLSTM was intended to capture long-term trends in HDI, CO2 emissions, and material footprint over time.\n",
    "\t4.\tFitness Score Evaluation:\n",
    "\t•\tAt each step, the fitness scores were monitored, ensuring that improvements were achieved in the optimization objectives.\n",
    "\t•\tPareto-optimal solutions were identified, which represent the best possible trade-offs between HDI maximization and environmental minimization.\n",
    "\t5.\tVisualization and Analysis:\n",
    "\t•\tFitness Score Progression: Tracked over generations to observe the evolution of solutions, indicating how the model’s performance improved.\n",
    "\t•\tData Insights: Explored insights from feature importance (XGBoost/LightGBM) to understand which features contributed the most to human development and environmental sustainability optimization.\n",
    "\t•\tPareto Front Visualization (planned): To visualize the trade-offs between the objectives and interpret the best-performing solutions.\n",
    "\n",
    "Exact Objective\n",
    "\n",
    "The exact objective of this project is to develop a comprehensive multi-objective optimization model that achieves the following:\n",
    "\n",
    "\t1.\tMaximizes HDI: Striving for higher life expectancy, better education outcomes, and higher income levels globally.\n",
    "\t2.\tMinimizes Environmental Degradation:\n",
    "\t•\tReducing CO2 emissions per capita.\n",
    "\t•\tLowering the material footprint per capita.\n",
    "\t3.\tFind Pareto-Optimal Solutions:\n",
    "\t•\tImplement EGA and machine learning models to find solutions that balance all three objectives effectively.\n",
    "\t•\tIdentify trade-offs and generate actionable insights for global policies that promote sustainable human development.\n",
    "\n",
    "How the Outcome Can Be Beneficial\n",
    "\n",
    "\t1.\tPolicy Recommendations:\n",
    "\t•\tThis research can aid governments and organizations in crafting policies that support sustainable development, addressing trade-offs between growth and sustainability.\n",
    "\t2.\tReal-World Applications:\n",
    "\t•\tThe model’s results can be used for time-series forecasting of sustainable human development trajectories, offering guidance on achieving both development and sustainability goals simultaneously.\n",
    "\t3.\tInsightful Decision-Making:\n",
    "\t•\tThe findings can help stakeholders understand which indicators require more attention, which ones show promising trends, and which policies need adjustments to balance human development and environmental impact.\n",
    "\n",
    "Next Steps\n",
    "\n",
    "\t1.\tComplete LSTM implementation: Ensure successful training and validation of the LSTM model.\n",
    "\t2.\tCombine Results from all three models and visualize the Pareto front to interpret trade-offs.\n",
    "\t3.\tImplement Extended Grid Search to refine hyperparameters and enhance model performance further.\n",
    "\t4.\tAnalyze Final Insights and draw conclusions on the best strategies for achieving sustainable human development.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Machine Learning Models for the Project\n",
    "\n",
    "Given the project’s objectives and the nature of the dataset, the three most suitable machine learning models identified so far are:\n",
    "\n",
    "\t1.\tXGBoost (Extreme Gradient Boosting)\n",
    "\t2.\tLightGBM (Light Gradient Boosting Machine)\n",
    "\t3.\tLSTM (Long Short-Term Memory)\n",
    "\n",
    "Here’s a detailed breakdown of why these models are considered the best for this project:\n",
    "\n",
    "1. XGBoost (Extreme Gradient Boosting)\n",
    "\n",
    "\t•\tWhy XGBoost?\n",
    "\t•\tHandles Non-Linear Relationships: XGBoost excels at capturing non-linear interactions between features, which is crucial given the complex relationships in human development and environmental indicators.\n",
    "\t•\tRobust Feature Importance: It provides clear insights into which features contribute the most to the model’s predictions, aiding interpretability—a critical aspect for policy recommendations.\n",
    "\t•\tHandles Missing Values Efficiently: XGBoost can manage missing values well, which is advantageous considering potential gaps in the dataset from 1990-2021.\n",
    "\t•\tScalability: XGBoost is highly scalable, making it suitable for large datasets and efficient training.\n",
    "\t•\tIntegration with Enhanced Genetic Algorithms (EGA) and Extended Grid Search:\n",
    "\t•\tEGA for Hyperparameter Optimization: EGA can be used to optimize key XGBoost hyperparameters like learning_rate, max_depth, n_estimators, etc., which improves the model’s performance in achieving Pareto-optimal trade-offs.\n",
    "\t•\tMulti-Objective Setup: EGA guides the optimization towards maximizing HDI while minimizing CO2 emissions and material footprint simultaneously.\n",
    "\t•\tExtended Grid Search for Refinement: Once EGA determines the optimal hyperparameter ranges, Extended Grid Search can further fine-tune the model’s performance.\n",
    "\t•\tStrengths for the Project:\n",
    "\t•\tPowerful performance for non-linear relationships.\n",
    "\t•\tGood balance of interpretability and accuracy.\n",
    "\t•\tWell-suited for handling imbalanced objectives, making it ideal for multi-objective optimization.\n",
    "\n",
    "2. LightGBM (Light Gradient Boosting Machine)\n",
    "\n",
    "\t•\tWhy LightGBM?\n",
    "\t•\tOptimized for Speed and Efficiency: LightGBM is faster than XGBoost, especially on large datasets, making it efficient for both training and deployment.\n",
    "\t•\tHandles Categorical Variables: LightGBM is more efficient with categorical variables, which is beneficial for certain categorical features in the dataset (e.g., human development groups, gender disparities).\n",
    "\t•\tMemory Efficiency: It uses less memory, allowing efficient computation in multi-objective optimization tasks.\n",
    "\t•\tFeature Interpretability: Similar to XGBoost, it provides feature importance metrics that help identify critical indicators affecting human development and sustainability.\n",
    "\t•\tIntegration with Enhanced Genetic Algorithms (EGA) and Extended Grid Search:\n",
    "\t•\tEGA for Hyperparameter Tuning: Key hyperparameters like num_leaves, max_depth, learning_rate, and min_child_samples can be optimized using EGA, aligning the model with the project’s objectives.\n",
    "\t•\tMulti-Objective Optimization: EGA helps maximize HDI while minimizing CO2 and material footprint in a more efficient manner compared to XGBoost.\n",
    "\t•\tExtended Grid Search: It can be used to further refine the model’s hyperparameters, improving performance beyond EGA optimization.\n",
    "\t•\tStrengths for the Project:\n",
    "\t•\tFaster and more efficient than XGBoost.\n",
    "\t•\tExcellent performance with time-series data, which suits the dataset covering 1990-2021.\n",
    "\t•\tGood for explaining feature importance in multi-objective contexts.\n",
    "\n",
    "3. LSTM (Long Short-Term Memory)\n",
    "\n",
    "\t•\tWhy LSTM?\n",
    "\t•\tHandles Time-Series Data Effectively: LSTM is designed to capture long-term dependencies and sequential patterns, making it highly suitable for time-series forecasting of HDI, CO2 emissions, and material footprint.\n",
    "\t•\tCaptures Sequential Patterns: It can identify trends and changes over time, which aligns with the project’s need to analyze long-term development patterns from 1990 to 2021.\n",
    "\t•\tVersatility: LSTM can manage both linear and non-linear relationships, providing flexibility in understanding the interactions between development and sustainability indicators.\n",
    "\t•\tIntegration with Enhanced Genetic Algorithms (EGA) and Extended Grid Search:\n",
    "\t•\tEGA for Model Optimization: Key hyperparameters like the number of layers, units per layer, batch size, learning rate, and dropout rate can be optimized using EGA, leading to better multi-objective performance.\n",
    "\t•\tSequential Optimization: LSTM can be used to sequentially predict future HDI, CO2, and material footprint trends, guided by EGA to optimize parameters that balance the three objectives.\n",
    "\t•\tExtended Grid Search: It can further refine LSTM’s architecture for better performance in forecasting long-term trends.\n",
    "\t•\tStrengths for the Project:\n",
    "\t•\tBest suited for long-term dependencies in time-series data.\n",
    "\t•\tCaptures non-linear dynamics in human development and sustainability.\n",
    "\t•\tProvides sequential insights into future projections, supporting long-term policy development.\n",
    "\n",
    "Best Model for the Project\n",
    "\n",
    "While all three models have their strengths, LightGBM and XGBoost are likely to be more efficient in achieving immediate multi-objective optimization goals, given their interpretability and speed. LSTM is more suited for the sequential, time-series forecasting aspect of the project, providing long-term insights.\n",
    "\n",
    "Therefore, the best strategy would be:\n",
    "\n",
    "\t1.\tCombine XGBoost and LightGBM for accurate and interpretable results in identifying the current Pareto-optimal solutions.\n",
    "\t2.\tUse LSTM as a complementary model to forecast future trends and evaluate long-term development paths.\n",
    "\t3.\tLeverage EGA and Extended Grid Search to ensure that the hyperparameters of these models are optimized to balance HDI maximization and environmental minimization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result\n",
    "\n",
    "    HDI_5yr_Rolling_Avg\tGNI_5yr_Rolling_Avg\tLife_Expectancy_5yr_Rolling_Avg\n",
    "    0\t0.419192\t1684.413291\t59.347881\n",
    "    1\t0.520192\t5732.510784\t54.429715\n",
    "    2\t0.737346\t9563.681523\t77.062762\n",
    "    3\t0.839962\t50283.611771\t82.019400\n",
    "    4\t0.838500\t78702.467077\t77.068327\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    HDI_Growth_1991\tHDI_Growth_1992\tHDI_Growth_1993\tHDI_Growth_1994\tHDI_Growth_1995\tHDI_Growth_1996\tHDI_Growth_1997\tHDI_Growth_1998\tHDI_Growth_1999\tHDI_Growth_2000\t...\tGNI_Growth_2012\tGNI_Growth_2013\tGNI_Growth_2014\tGNI_Growth_2015\tGNI_Growth_2016\tGNI_Growth_2017\tGNI_Growth_2018\tGNI_Growth_2019\tGNI_Growth_2020\tGNI_Growth_2021\n",
    "    0\t0.021978\t0.028674\t0.034843\t-0.016835\t0.061644\t0.029032\t0.012539\t0.003096\t0.024691\t0.009036\t...\t0.063116\t0.031842\t-0.006860\t-0.035308\t-0.011431\t0.003812\t-0.014648\t0.020901\t-0.047685\t-0.086924\n",
    "    1\t-0.027821\t-0.023847\t0.004886\t0.011345\t0.016026\t0.017350\t-0.004651\t0.023364\t-0.445967\t0.030220\t...\t0.057412\t0.027093\t0.030239\t-0.006694\t-0.060532\t-0.045602\t-0.069963\t-0.046819\t-0.080491\t-0.022800\n",
    "    2\t-0.027821\t-0.023847\t0.004886\t0.011345\t0.016026\t0.017350\t-0.004651\t0.023364\t0.018265\t0.011958\t...\t0.008105\t0.036489\t0.012003\t0.027768\t0.038974\t0.025433\t0.039100\t0.013727\t-0.036228\t0.087279\n",
    "    3\t0.015110\t0.004060\t0.008086\t0.009358\t0.009272\t0.006562\t0.007823\t0.007762\t0.010270\t0.039390\t...\t-0.034525\t-0.015739\t0.045244\t0.029972\t0.046676\t0.007318\t0.015823\t0.018356\t-0.120929\t0.068673\n",
    "    4\t0.015110\t0.004060\t0.008086\t0.009358\t0.009272\t0.006562\t0.007823\t0.007762\t0.010270\t0.011436\t...\t0.023043\t0.044559\t0.042793\t0.048008\t0.019882\t0.011755\t-0.006981\t0.020772\t-0.081272\t-0.007027\n",
    "5 rows × 62 columns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    HDI_Male_Female_Disparity\tLife_Expectancy_Male_Female_Disparity\tGNI_Male_Female_Disparity\n",
    "    0\t0.170771\t-6.3644\t2556.315050\n",
    "    1\t0.059813\t-5.2775\t1445.277229\n",
    "    2\t-0.005617\t-5.0857\t4992.686440\n",
    "    3\t0.043499\t-7.1515\t48396.535350\n",
    "    4\t0.043499\t-3.7207\t48396.535350\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    HDI_5yr_Rolling_Avg\tGNI_5yr_Rolling_Avg\tLife_Expectancy_5yr_Rolling_Avg\tCarbon dioxide emissions per capita (production) (tonnes) (2021)\tMaterial footprint per capita (tonnes) (2021)\tHDI_Male_Female_Disparity\tLife_Expectancy_Male_Female_Disparity\tGNI_Male_Female_Disparity\n",
    "    0\t0.154094\t0.007501\t0.300925\t0.007697\t0.010677\t0.673491\t0.442673\t0.039247\n",
    "    1\t0.320276\t0.042400\t0.161063\t0.017511\t0.020063\t0.294828\t0.551253\t0.021280\n",
    "    2\t0.677572\t0.075429\t0.804699\t0.041850\t0.146545\t0.071539\t0.570414\t0.078648\n",
    "    3\t0.846412\t0.426479\t0.945655\t0.162395\t0.803473\t0.239156\t0.364042\t0.780568\n",
    "    4\t0.844007\t0.671480\t0.804857\t0.409974\t0.803473\t0.239156\t0.706776\t0.780568\n",
    "\n",
    "\n",
    "Selected Features Shape: (195, 8)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evolution Results of Enhanced Genetic Algorithm (EGA)\n",
    "\n",
    "The Enhanced Genetic Algorithm (EGA) has successfully completed 100 generations, and the results are as follows:\n",
    "\n",
    "Final Results\n",
    "\n",
    "\t•\tBest Fitness Score after Evolution: 0.5521\n",
    "\t•\tThis represents the highest fitness score achieved, indicating the most balanced solution found by EGA based on maximizing HDI and minimizing CO2 emissions and material footprint per capita.\n",
    "\t•\tBest Individual after Evolution: [0.9877, 0.5496, 0.3741, 0.1528, 0.0380, 0.2178]\n",
    "\t•\tThis is the set of weights representing the optimal solution for our objectives.\n",
    "\n",
    "Interpreting the Best Individual\n",
    "\n",
    "The “best individual” consists of six weights corresponding to the selected features:\n",
    "\n",
    "\t1.\tHDI Rolling Average\n",
    "\t2.\tGNI Rolling Average\n",
    "\t3.\tLife Expectancy Rolling Average\n",
    "\t4.\tCO2 Emissions per Capita\n",
    "\t5.\tMaterial Footprint per Capita\n",
    "\t6.\tGender Disparity in HDI, Life Expectancy, and GNI\n",
    "\n",
    "The weights indicate the importance assigned to each feature by the algorithm:\n",
    "\n",
    "\t•\tHigher weights on HDI and GNI indicate a focus on maximizing human development.\n",
    "\t•\tLower weights on CO2 emissions and material footprint reflect the intention to minimize environmental impacts.\n",
    "\t•\tIntermediate weights on gender disparities suggest moderate importance for minimizing inequalities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
